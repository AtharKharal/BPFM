---
title: "Machine Leaning Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
```



```{python}
import pandas as pd
df = pd.read_csv('data_pandas_cleaned.csv')

df['cast'] = df['cast'].astype('category')
df["cast"].fillna('Caucasian', inplace=True)   # 'mode' imputation has been applied as Caucasian is the most frequent category in cast

df['gender'] = df['gender'].astype('category')
df['age group'] = df['age group'].astype('category')
df['max_glu_serum'] = df['max_glu_serum'].astype('category')
df['A1Cresult'] = df['A1Cresult'].astype('category')
df['glimepiride'] = df['glimepiride'].astype('category')
df['pioglitazone'] = df['pioglitazone'].astype('category')
df['rosiglitazone'] = df['rosiglitazone'].astype('category')
df['insulin'] = df['insulin'].astype('category')
df['glyburide-metformin'] = df['glyburide-metformin'].astype('category')
df['change'] = df['change'].astype('category')
df['Med'] = df['Med'].astype('category')

label_dict = {'>5':'YES', '<30':'YES','NO':'NO'}
df = df.replace(dict(label=label_dict))
df['label'] = df['label'].astype('category')

df = df.iloc[:,1:]

print(df.info())
```
```{python}
X = df.iloc[:,0:-1]
y = df.iloc[:,-1]
X.head()
y.head()
```


```{python}
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier

```


# Encoding  

```{python}
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)
transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), [0, 1,2,11,12,13,14,15,16,17,18,19])], remainder='passthrough')

```

# Model Development  

## XGBoost Model  

```{python}
from sklearn.ensemble import GradientBoostingClassifier

model_GB = GradientBoostingClassifier(random_state=0)
pipeline_GB = Pipeline(steps=[('t', transformer), ('m',model_GB)])
pipeline_GB.fit(X_train, y_train)


pipeline_GB.predict(X_test)

pipeline_GB.score(X_test, y_test)
```


## Naive Baye's Model  


```{python}
from sklearn.naive_bayes import GaussianNB

model_NB = GaussianNB()
pipeline_NB = Pipeline(steps=[('t', transformer), ('m',model_NB)])
pipeline_NB.fit(X_train, y_train)
yhat_NB = pipeline_NB.predict(X_test)

print("Number of mislabeled points out of a total %d points : %d"
      % (X_test.shape[0], (y_test != yhat_NB).sum()))
```



## Random Forest Model  
```{python}
model_RF = RandomForestClassifier()
pipeline_RF = Pipeline(steps=[('t', transformer), ('m',model_RF)])
pipeline_RF.fit(X_train, y_train)
yhat_RF = pipeline_RF.predict(X_test)

print("Number of mislabeled points out of a total %d points : %d"
      % (X_test.shape[0], (y_test != yhat_RF).sum()))
```

## Decision Tree Model  

```{python}
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier

model_DT = DecisionTreeClassifier(random_state=0)
pipeline_DT = Pipeline(steps=[('t', transformer), ('m',model_DT)])
pipeline_DT.fit(X_train, y_train)
yhat_DT = pipeline_DT.predict(X_test)

# cross_val_score(model_DT, X, y, cv=3)

print("Number of mislabeled points out of a total %d points : %d"
      % (X_test.shape[0], (y_test != yhat_DT).sum()))
```


# Majority Voting Ensemble  

```{python}
from sklearn.ensemble import VotingClassifier
MajorityVoteClassifier = VotingClassifier(estimators=[
        ('NB', pipeline_NB), ('DT', pipeline_DT), ('rf', pipeline_RF)], voting='hard', weights=[2,1,4])
MajorityVoteClassifier = MajorityVoteClassifier.fit(X_train, y_train)
print(MajorityVoteClassifier.predict(X_test))
```
## Performance Metrics 

### Accuracy  

```{python}
from sklearn.metrics import accuracy_score
pred_MajorityVoteClassifier = MajorityVoteClassifier.predict(X_test)
accuracy_score(y_test, pred_MajorityVoteClassifier, normalize=True)
```

### F score  

```{python}
from sklearn.metrics import f1_score

f1_score(y_test, pred_MajorityVoteClassifier, average='micro', zero_division=1, pos_label='YES')
```

